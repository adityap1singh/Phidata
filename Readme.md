Data Analysis Agent with Agno
ğŸ” Overview
This is a low-code AI application built with Agno (formerly Phidata), designed to analyze CSV files, summarize key statistics, embed metadata, and retrieve similar datasets using semantic search. It leverages Google Gemini for natural language understanding, SentenceTransformers for embeddings, and Pinecone as a vector store, all integrated through a Streamlit interface.
ğŸ“˜ Scenario
Suppose a data analyst is working with multiple CSV datasets and wants to quickly:
â€¢	Understand the structure and statistical summary of each dataset,
â€¢	Index summaries for fast semantic retrieval,
â€¢	Search for similar datasets based on metadata patterns.
This tool automates that workflow â€” uploading a CSV file generates a summary, stores metadata embeddings in Pinecone, and enables natural language queries to retrieve similar datasets.
ğŸ§© Problem Statement
Create a CSV Data Insights application that:
â€¢	Accepts user-uploaded CSV files,
â€¢	Describes the data using statistical summaries,
â€¢	Chunks and embeds summaries using SentenceTransformers,
â€¢	Stores embeddings in Pinecone for semantic search,
â€¢	Allows querying for similar datasets,
â€¢	Presents results in an easy-to-use Streamlit UI.
________________________________________
ğŸ› ï¸ Features
â€¢	ğŸ“‚ Upload and analyze CSV files
â€¢	ğŸ“ˆ View detailed data summaries
â€¢	ğŸ§© Chunk & embed summary metadata
â€¢	ğŸ§  Store and search using Pinecone vector DB
â€¢	ğŸ” Query similar datasets with semantic search
â€¢	ğŸ“¤ Download dataset summaries as CSV
________________________________________
ğŸ§  Tech Stack
â€¢	Phidata (Agno) â€“ Agent framework and workflow orchestration
â€¢	Google Gemini API â€“ Natural language generation
â€¢	SentenceTransformers â€“ Text embedding via all-MiniLM-L6-v2
â€¢	Pinecone â€“ Vector store for semantic search
â€¢	Streamlit â€“ Frontend interface
â€¢	dotenv â€“ Environment configuration
________________________________________

ğŸ“¦ Project Structure
â”œâ”€â”€ app.py                # Streamlit frontend and main app logic
â”œâ”€â”€ .env                  # API key and environment variables
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation
________________________________________
âš™ï¸ Setup Instructions
1. Clone the Repository
git clone https://github.com/your-username/csv-data-insights.git
cd csv-data-insights
2. Create and Activate Virtual Environment
python -m venv venv
source venv/bin/activate      # or venv\Scripts\activate on Windows
3. Install Dependencies
pip install -r requirements.txt
4. Add API Keys
Create a .env file in the root directory and add:
GOOGLE_API_KEY=your_google_api_key
PINECONE_API_KEY=your_pinecone_api_key
5. Run the Application
streamlit run app4.py
________________________________________
ğŸ“š Key Concepts in Use
â€¢	âœ… Agent: Orchestrates tools to run analysis workflows
â€¢	ğŸ§° Tools: Describe CSV, Embed & Store metadata, Search similar
â€¢	âœ‚ï¸ Chunking: Metadata split into digestible parts for embedding
â€¢	ğŸ§  Embeddings: Using all-MiniLM-L6-v2 for semantic similarity
â€¢	ğŸ“¦ Vector Store: Pinecone for persistent embedding storage
â€¢	ğŸ–¼ï¸ LLM: Google Gemini for question-answering and UI responses
â€¢	ğŸ–¥ï¸ UI: Streamlit frontend for file upload and report interaction
________________________________________
ğŸ“ˆ Example Output
Dataset Summary:
	age	employee_satisfaction	recent_salary	prior_salary	last_raise	employee_id
count	1821	1821	1821	1821	1821	1821	
mean	47.4849	65.34761	124521.5	117041	7480.488	2E+09	
std	7.37373	20.59141	43997.97	41595.74	6361.387	525.8217	
min	35	30	50011	43975	0	2E+09	
25%	41	47	85275	80658	1962	2E+09	
50%	47	65	124544	116950	6318	2E+09	
75%	54	84	162981	153402	11720	2E+09	
max	61	100	199951	199742	25995	2E+09	
							

Semantic Query: "Find datasets similar to sales data from Q2"
Results:
ID: uploaded_data.csv_chunk_0, Score: 0.87
ID: sales_2023_chunk_3, Score: 0.85
...
________________________________________
ğŸ‘¤ Ideal For
â€¢	Data analysts and data scientists
â€¢	Educators teaching data summarization and semantic search
â€¢	Developers building intelligent CSV analysis pipelines
